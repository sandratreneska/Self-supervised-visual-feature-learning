{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VOC-Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandratreneska/Self-supervised-visual-feature-learning/blob/main/VOC_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPI1pudjmjh5",
        "outputId": "742ea721-4877-414d-dd28-6a40752d9161"
      },
      "source": [
        "!pip install scikit-multilearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71 kB 19.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 89 kB 6.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcegE3hGaffx"
      },
      "source": [
        "import os\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import math\n",
        "import pickle\n",
        "from keras import utils\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.models import Model\n",
        "from keras.models import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn import preprocessing\n",
        "from skimage.color import rgb2lab\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "from skmultilearn.model_selection import IterativeStratification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqYOeaFbGANq",
        "outputId": "6bd6466e-6e02-4a79-d574-f6e939bc5b88"
      },
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ycyyIg8MkCd",
        "outputId": "a664948d-ab36-4841-d78d-927d08755396"
      },
      "source": [
        "# Check if GPU is connected\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsFaWzuVdel-"
      },
      "source": [
        "# Directories and parameters\n",
        "DIR = '/content/drive/My Drive/Self-supervised-VOC/'\n",
        "directory_annotations = DIR + 'VOC2012/Annotations/'\n",
        "directory_images = DIR + 'VOC2012/JPEGImages/'\n",
        "saved_weights_path = DIR + 'SavedWeights/'\n",
        "saved_models_path = DIR + 'SavedModels/'\n",
        "model_name = 'scratch-class-coco-balanced' # change\n",
        "GEN_PATH = DIR + 'PretrainedGenerator/pix2pixCOCO.h5' # change\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE_1 = 3e-4\n",
        "LEARNING_RATE_2 = 5e-5 # 3e-4 change\n",
        "EPOCHS = 10 # 20  change\n",
        "NUM_CLASSES = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soDfLeq5aznl"
      },
      "source": [
        "# Save image names\n",
        "filenames = []\n",
        "i = 0\n",
        "for xml_file in os.listdir(directory_annotations):\n",
        "    if os.path.isfile(directory_annotations + xml_file):\n",
        "      imgname = xml_file.strip('.xml')\n",
        "      #print(imgname)\n",
        "      filenames.append(imgname)\n",
        "      print(i)\n",
        "      i = i + 1\n",
        "\n",
        "print(filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsmzZg1MmQPA",
        "outputId": "43e124a0-df7b-4159-a0db-46d3a7d11888"
      },
      "source": [
        "# Encode the labels\n",
        "labelnames = preprocessing.LabelEncoder()\n",
        "labelnames.fit([\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\",\n",
        "                \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\",\n",
        "                \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "picAlM_djQ8k"
      },
      "source": [
        "# Return the image and its label, from a given filename\n",
        "def generate_from_xml(filename):\n",
        "  label = np.zeros((NUM_CLASSES), dtype = 'float32')\n",
        "  tree = ET.parse(os.path.join(directory_annotations, filename + \".xml\"))\n",
        "  #raw_image = cv2.imread(os.path.join(directory_images, filename + \".jpg\")) # read image\n",
        "  raw_image = tf.keras.preprocessing.image.load_img(os.path.join(directory_images, filename + \".jpg\"), color_mode='rgb', target_size= (IMG_HEIGHT,IMG_WIDTH))\n",
        "  res_img = np.array(raw_image, dtype=np.float32)\n",
        "  #res_img = cv2.resize(raw_image, (IMG_WIDTH,IMG_HEIGHT)) # resize image\n",
        "\n",
        "  # Preprocess\n",
        "  res_img = res_img / 255. # to srgb [0, 1]\n",
        "  lab_img = rgb2lab(res_img)  # convert from srgb to lab\n",
        "  gray_lab = lab_img[:, :, 0] / 50. - 1.  # grayscale layer, between [-1, 1]\n",
        "  color_lab = lab_img[:, :, 1:] / 128.  # green-red and blue-yellow layers, normalize between [-1, 1]\n",
        "  img = np.zeros((IMG_WIDTH, IMG_HEIGHT, 3))  # zeroes matrix\n",
        "  img[:, :, 0] = gray_lab  # grayscale, change with only grayscale\n",
        "  img[:, :, 1:] = color_lab  # original two layers\n",
        "\n",
        "  gray_lab = gray_lab.reshape(gray_lab.shape + (1,)) # convert from (256,256) to (256,256,1)\n",
        "\n",
        "  # Find the labels ex. [1 0 0 1 ...] multiclass\n",
        "  for elems in tree.iter():\n",
        "    if elems.tag == \"object\":\n",
        "      name = elems.find(\"name\").text\n",
        "      labelnr = labelnames.transform([name])[0]\n",
        "      label[labelnr] = 1\n",
        "      \n",
        "  return gray_lab, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVRH76k8CC8B"
      },
      "source": [
        "def iterative_train_test_split(X, y, train_size):\n",
        "    \"\"\"Custom iterative train test split which\n",
        "    'maintains balanced representation with respect\n",
        "    to order-th label combinations.'\n",
        "    \"\"\"\n",
        "    stratifier = IterativeStratification(\n",
        "        n_splits=2, order=1, sample_distribution_per_fold=[1.0-train_size, train_size, ])\n",
        "    train_indices, test_indices = next(stratifier.split(X, y))\n",
        "    X_train, y_train = X[train_indices], y[train_indices]\n",
        "    X_test, y_test = X[test_indices], y[test_indices]\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfqdV_ajeGjH"
      },
      "source": [
        "# Indexes for splitting the dataset into train, val, test\n",
        "\n",
        "'''\n",
        "filecount = len(filenames)\n",
        "indexes = []\n",
        "labels = []\n",
        "for index in range(filecount):\n",
        "     indexes.append(index)\n",
        "\n",
        "for filename in filenames:\n",
        "    _, label = generate_from_xml(filename)\n",
        "    labels.append(label)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dSNx2DVCJNs"
      },
      "source": [
        "'''\n",
        "indexes = np.array(indexes)\n",
        "labels = np.array(labels)\n",
        "training_indexes, X_valtest, y_train, y_valtest = iterative_train_test_split(indexes, labels, train_size = 0.7)\n",
        "validation_indexes, testing_indexes, y_val, y_test = iterative_train_test_split(X_valtest, y_valtest, train_size = 0.66)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrZj8rvdCQPc"
      },
      "source": [
        "'''\n",
        "print(len(training_indexes))\n",
        "print(len(y_train))\n",
        "print(len(testing_indexes))\n",
        "print(len(y_test))\n",
        "print(training_indexes[3100:3150])\n",
        "print(y_train[3000:3010])\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or2wUXGV3tzy"
      },
      "source": [
        "'''\n",
        "num_train_samples = len(training_indexes)\n",
        "num_val_samples = len(validation_indexes)\n",
        "num_test_samples = len(testing_indexes)\n",
        "\n",
        "print(\"Num. training images\", num_train_samples)\n",
        "print(\"Num. val images\", num_val_samples)\n",
        "print(\"Num. test images\", num_test_samples)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UXk6vImxTj9"
      },
      "source": [
        "# Save train, val, test index splits\n",
        "'''\n",
        "np.savetxt(DIR + 'VOC2012/Classification_indexes/class_train_indexes.txt', training_indexes, fmt='%d')\n",
        "np.savetxt(DIR + 'VOC2012/Classification_indexes/class_val_indexes.txt', validation_indexes, fmt='%d')\n",
        "np.savetxt(DIR + 'VOC2012/Classification_indexes/class_test_indexes.txt', testing_indexes, fmt='%d')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbd-TDzFxfLM"
      },
      "source": [
        "# Load train, val, test index splits\n",
        "training_indexes = np.loadtxt(DIR + 'VOC2012/Classification_indexes/class_train_indexes.txt', dtype=int)\n",
        "validation_indexes = np.loadtxt(DIR + 'VOC2012/Classification_indexes/class_val_indexes.txt', dtype=int)\n",
        "testing_indexes = np.loadtxt(DIR + 'VOC2012/Classification_indexes/class_test_indexes.txt', dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I1yfKGKagRR"
      },
      "source": [
        "# Example\n",
        "img, label = generate_from_xml('2007_000063')\n",
        "#print(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voi8TmsXfMJv"
      },
      "source": [
        "class DataGenerator(utils.all_utils.Sequence):\n",
        "  \n",
        "\n",
        "  def __init__(self, list_IDs, datafiles, batch_size = BATCH_SIZE, n_classes = NUM_CLASSES, shuffle = True):\n",
        "    self.batch_size = batch_size\n",
        "    self.datafiles = datafiles\n",
        "    self.list_IDs = list_IDs\n",
        "    self.n_classes = n_classes\n",
        "    self.shuffle = shuffle\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  # After each epoch, shuffle the images if true\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(len(self.list_IDs))\n",
        "    if self.shuffle == True:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  # Generate images and labels for a batch\n",
        "  def __data_generation(self, list_IDs_temp):\n",
        "\n",
        "    # Initialization\n",
        "    X = np.empty((self.batch_size, IMG_WIDTH, IMG_HEIGHT, 1))\n",
        "    y = np.empty((self.batch_size, NUM_CLASSES))\n",
        "\n",
        "    # For every image in the batch\n",
        "    for datactr in range (self.batch_size):\n",
        "      newimg, newlabel = generate_from_xml(self.datafiles[list_IDs_temp[datactr]])\n",
        "\n",
        "      y[datactr] = newlabel\n",
        "    \n",
        "      X[datactr] = newimg\n",
        "\n",
        "    return X, y\n",
        "\n",
        "  # Number of batches per epoch\n",
        "  def __len__(self):\n",
        "    return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "  # Generate indexes of the batch\n",
        "    newindexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "  # Find list of IDs\n",
        "    list_IDs_temp = [self.list_IDs[k] for k in newindexes]\n",
        "\n",
        "  # Generate data\n",
        "    X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf7YepegfOyn"
      },
      "source": [
        "training_generator = DataGenerator(training_indexes, filenames)\n",
        "val_generator = DataGenerator(validation_indexes, filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9OzEuWyXqmd"
      },
      "source": [
        "# define an encoder block\n",
        "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
        "    # weight initialization\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    # add downsampling layer\n",
        "    g = Conv2D(n_filters, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(layer_in)\n",
        "    # conditionally add batch normalization\n",
        "    if batchnorm:\n",
        "        g = BatchNormalization()(g, training=True)\n",
        "    # leaky relu activation\n",
        "    g = LeakyReLU(alpha=0.2)(g)\n",
        "    return g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_tS_kiZXrWo"
      },
      "source": [
        "# define the classification model\n",
        "def define_model(image_shape=(IMG_WIDTH, IMG_HEIGHT, 1)): # change channels to one\n",
        "    # weight initialization\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    # image input\n",
        "    in_image = Input(shape=image_shape)\n",
        "    # encoder model: C64-C128-C256-C512-C512-C512-C512-C512\n",
        "    e1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
        "    e2 = define_encoder_block(e1, 128)\n",
        "    e3 = define_encoder_block(e2, 256)\n",
        "    e4 = define_encoder_block(e3, 512)\n",
        "    e5 = define_encoder_block(e4, 512)\n",
        "    e6 = define_encoder_block(e5, 512)\n",
        "    e7 = define_encoder_block(e6, 512)\n",
        "    # bottleneck, no batch norm and relu\n",
        "    b = Conv2D(512, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(e7)\n",
        "    b = Activation('relu')(b)\n",
        "    x = Flatten()(b)  # Flatten dimensions for use in FC layers\n",
        "    x = Dense(4096, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(4096, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    out_image = Dense(NUM_CLASSES, activation='sigmoid')(x)\n",
        "    classification_model = keras.Model(inputs=in_image, outputs=out_image)\n",
        "\n",
        "    return classification_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orih-O7Dpn-2"
      },
      "source": [
        "def define_model_pretrained():\n",
        "\n",
        "  # load pre-trained generator\n",
        "  g_model = keras.models.load_model(GEN_PATH)\n",
        "  # change freezed or not\n",
        "  #g_model.trainable = False\n",
        "\n",
        "  # get the encoder\n",
        "  bottleneck_layer = 'activation'\n",
        "  encoder = keras.Model(inputs=g_model.input, outputs=g_model.get_layer(bottleneck_layer).output)\n",
        "  print(encoder.summary())\n",
        "\n",
        "  # adding a classifier like VGG and Alexnet\n",
        "  x = encoder.output\n",
        "  x = Flatten()(x)  # Flatten dimensions for use in FC layers\n",
        "  x = Dense(4096, activation='relu')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(4096, activation='relu')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "\n",
        "  output = Dense(20, activation='sigmoid')(x)  # make num nodes with variable\n",
        "  classification_model = keras.Model(inputs=encoder.input, outputs=output)\n",
        "\n",
        "  return classification_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msOp3fkPYkRh"
      },
      "source": [
        "model = define_model()\n",
        "#model = define_model_pretrained() # change\n",
        "model.load_weights(saved_weights_path+'saved-weights-scratch-class-coco-balanced-04-0.17.hdf5')  #change"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-yOH0FhZWAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62d41437-52e3-423d-bd09-2ad71ba27762"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_1), loss='binary_crossentropy', metrics=['accuracy'])  # change lr\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 256, 256, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 128, 128, 64)      1088      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 64, 64, 128)       131200    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 256)       524544    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 512)       2097664   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 512)         4194816   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 4, 512)         4194816   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 2, 2, 512)         4194816   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 1, 1, 512)         4194816   \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              2101248   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20)                81940     \n",
            "=================================================================\n",
            "Total params: 38,507,988\n",
            "Trainable params: 38,503,124\n",
            "Non-trainable params: 4,864\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZNjGMTYbInF"
      },
      "source": [
        "#earlyStopping = EarlyStopping(monitor='val_loss', verbose=0, mode='min', patience = 4) # patience - Number of epochs with no improvement after which training will be stopped\n",
        "weights_save = ModelCheckpoint(saved_weights_path+'saved-weights-' + model_name + '-{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_weights_only=True, save_freq='epoch')\n",
        "\n",
        "history = model.fit(training_generator, \n",
        "validation_data=val_generator,\n",
        "use_multiprocessing=True,\n",
        "workers=6,\n",
        "epochs=EPOCHS,\n",
        "callbacks=[weights_save])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVs-u_ogzLXk"
      },
      "source": [
        "df = pd.DataFrame(history.history)\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkQEg6qwzSlz"
      },
      "source": [
        "#load in the test set\n",
        "labels_test = []\n",
        "images_test = []\n",
        "for testing_index in testing_indexes:\n",
        "  image_test, label_test = generate_from_xml(filenames[testing_index])\n",
        "  labels_test.append(label_test)\n",
        "  images_test.append(image_test)\n",
        "  print(testing_index)\n",
        "\n",
        "images_test = np.array(images_test)\n",
        "labels_test = np.array(labels_test)\n",
        "\n",
        "loss, acc = model.evaluate(x=images_test,  y=labels_test, verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100*acc))\n",
        "print('Restored model, loss', loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggCo_eMOBO00"
      },
      "source": [
        "y_pred = model.predict(images_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MozA_YMHMxPY"
      },
      "source": [
        "# Save history\n",
        "with open(DIR + 'TrainHistory/class_coco_balanced_history', 'wb') as file_pi: # change name\n",
        "    pickle.dump(history.history, file_pi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITFPmtF6zdNH",
        "outputId": "6c42e889-3d3a-4497-e562-1d618924eccc"
      },
      "source": [
        "# Save  model\n",
        "model.save(saved_models_path + 'saved-model-' + model_name) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Self-supervised-VOC/SavedModels/saved-model-scratch-class-coco-balanced/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh8xmmqYHlsU"
      },
      "source": [
        "# Classification report\n",
        "labels =[\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\",\n",
        "                \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\",\n",
        "                \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
        "y_pred = (y_pred > 0.5) # threshold 0.5\n",
        "print(classification_report(labels_test, y_pred, target_names=labels))\n",
        "\n",
        "class_accuracies = []\n",
        "for class_ in np.unique(labels_test):\n",
        "    class_acc = np.mean(y_pred[labels_test == class_] == class_)\n",
        "    class_acuracies.append(class_acc)\n",
        "\n",
        "print(class_acuracies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3_HqbFWEWNl"
      },
      "source": [
        "# Confusion matrix\n",
        "cm = multilabel_confusion_matrix(labels_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "\n",
        "#disp.plot(cmap=plt.cm.Blues)\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJIVW48WqgXC"
      },
      "source": [
        "## Loss Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "_ndKoiBQqipU",
        "outputId": "7c9b7280-f61a-4036-b208-6d01aac0914d"
      },
      "source": [
        "epochs = [1,2,3,4]\n",
        "train_loss_scratch = np.array([0.2122, 0.1962, 0.1881, 0.1808])\n",
        "train_loss_pre = np.array([0.1954, 0.1596, 0.1370, 0.0993])\n",
        "\n",
        "# Plotting both the curves simultaneously\n",
        "plt.plot(epochs, train_loss_scratch, color='g', label='From scratch')\n",
        "plt.plot(epochs, train_loss_pre, color='royalblue', label='From colorization init')\n",
        "  \n",
        "# Naming the x-axis, y-axis and the whole graph\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training loss\")\n",
        "  \n",
        "# Adding legend, which helps us recognize the curve according to it's color\n",
        "plt.legend()\n",
        "  \n",
        "# To load the display window\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}