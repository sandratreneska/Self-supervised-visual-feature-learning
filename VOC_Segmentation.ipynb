{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VOC-Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandratreneska/Self-supervised-visual-feature-learning/blob/main/VOC_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suQbCPx_FWin",
        "outputId": "39e7e953-1843-4d82-8e07-e719b4f1c0c1"
      },
      "source": [
        "!pip install scikit-multilearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 89 kB 3.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J3i7Tjhsn6p"
      },
      "source": [
        "import os\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import math\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.models import Model\n",
        "from keras.models import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import utils\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "from skmultilearn.model_selection import IterativeStratification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnIS1TOXiU7x",
        "outputId": "87e37917-7f7e-4d40-fc08-0cff362a0276"
      },
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbq96ngNiXEG",
        "outputId": "92e7d1b2-8f5c-481c-e794-4ba85fc33275"
      },
      "source": [
        "# Check if GPU is connected\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "341xCY7Libv0"
      },
      "source": [
        "# Directories and parameters\n",
        "DIR = '/content/drive/My Drive/Self-supervised-VOC/'\n",
        "directory_annotations = DIR + 'VOC2012/Annotations/'\n",
        "directory_segmentations = DIR + 'VOC2012/SegmentationClass/'\n",
        "directory_images = DIR + 'VOC2012/JPEGImages/'\n",
        "saved_weights_path = DIR + 'SavedWeights/'\n",
        "saved_models_path = DIR + 'SavedModels/'\n",
        "model_name = 'seg-coco-balanced-pretrained' # change\n",
        "GEN_PATH = DIR + 'PretrainedGenerator/pix2pixCOCO.h5' # change\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE_1 = 3e-4\n",
        "LEARNING_RATE_2 = 5e-5\n",
        "EPOCHS = 10 # 20  change\n",
        "NUM_CLASSES = 21"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Gg2JtgLMKtr"
      },
      "source": [
        "# Save image names\n",
        "filenames = []\n",
        "i = 0\n",
        "for xml_file in os.listdir(directory_segmentations):\n",
        "    if os.path.isfile(directory_segmentations + xml_file):\n",
        "      imgname = xml_file.strip('.png')\n",
        "      #print(imgname)\n",
        "      filenames.append(imgname)\n",
        "      print(i)\n",
        "      i = i + 1\n",
        "\n",
        "print(filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0DGDrbcYts7"
      },
      "source": [
        "VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
        "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
        "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
        "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
        "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
        "                [0, 64, 128]]\n",
        "\n",
        "VOC_CLASSES = [\n",
        "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
        "    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
        "    'person', 'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG5F8tRzMemE"
      },
      "source": [
        "def voc_colormap2label():\n",
        "    \"\"\"Build the mapping from RGB to class indices for VOC labels.\"\"\"\n",
        "    colormap2label = np.zeros(256**3)\n",
        "    for i, colormap in enumerate(VOC_COLORMAP):\n",
        "        #print(i)\n",
        "        colormap2label[(colormap[0] * 256 + colormap[1]) * 256 +\n",
        "                       colormap[2]] = i\n",
        "    return colormap2label\n",
        "\n",
        "def voc_label_indices(colormap, colormap2label):\n",
        "    \"\"\"Map any RGB values in VOC labels to their class indices.\"\"\"\n",
        "    colormap = colormap.astype(np.int32)\n",
        "    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256 +\n",
        "           colormap[:, :, 2])\n",
        "    return colormap2label[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRS3Y-92sYi5"
      },
      "source": [
        "def voc_rand_crop(image, mask, height, width):\n",
        "    \"\"\"Randomly crop both feature and label images.\"\"\"\n",
        "    #feature, rect = image.random_crop(feature, (width, height))\n",
        "    #label = image.fixed_crop(label, *rect)\n",
        "    resized_image = cv2.resize(image, (width, height), interpolation=cv2.INTER_NEAREST)\n",
        "    resized_mask = cv2.resize(mask, (width, height), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    return resized_image, resized_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPssc7pztWxL"
      },
      "source": [
        "def read_image_and_label(filename):\n",
        "\n",
        "  # Image\n",
        "  raw_image = tf.keras.preprocessing.image.load_img(os.path.join(directory_images, filename + \".jpg\"), color_mode='rgb') # read image\n",
        "  raw_image = np.array(raw_image, dtype=np.float32)\n",
        "\n",
        "  # Preprocess\n",
        "  res_img = raw_image / 255. # to srgb\n",
        "  lab_img = rgb2lab(res_img)  # convert from srgb to lab\n",
        "  gray_lab = lab_img[:, :, 0] / 50. - 1.  # grayscale layer, between [-1, 1]\n",
        "  gray_lab = gray_lab.reshape(gray_lab.shape + (1,))\n",
        "\n",
        "  # Label\n",
        "  raw_label = tf.keras.preprocessing.image.load_img(os.path.join(directory_segmentations, filename + \".png\"), color_mode='rgb') # read segmentation image\n",
        "  raw_label = np.array(raw_label, dtype=np.float32)\n",
        "\n",
        "  final_img, final_label = voc_rand_crop(gray_lab, raw_label, IMG_WIDTH, IMG_HEIGHT)\n",
        "  final_img = final_img.reshape(final_img.shape + (1,))\n",
        "  final_label = voc_label_indices(final_label, voc_colormap2label())\n",
        "  final_label = final_label.reshape(final_label.shape + (1,))\n",
        "\n",
        "  final_img = np.array(final_img, dtype=np.float32)\n",
        "  final_label = np.array(final_label, dtype=np.float32)\n",
        "\n",
        "  one_hot_label = tf.keras.utils.to_categorical(final_label, NUM_CLASSES)\n",
        "\n",
        "  return final_img, one_hot_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWuGDAio__R_"
      },
      "source": [
        "def iterative_train_test_split(X, y, train_size):\n",
        "    \"\"\"Custom iterative train test split which\n",
        "    'maintains balanced representation with respect\n",
        "    to order-th label combinations.'\n",
        "    \"\"\"\n",
        "    stratifier = IterativeStratification(\n",
        "        n_splits=2, order=1, sample_distribution_per_fold=[1.0-train_size, train_size, ])\n",
        "    train_indices, test_indices = next(stratifier.split(X, y))\n",
        "    X_train, y_train = X[train_indices], y[train_indices]\n",
        "    X_test, y_test = X[test_indices], y[test_indices]\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e4tIJrJv-aG"
      },
      "source": [
        "# Example\n",
        "img, label = read_image_and_label('2007_000063')\n",
        "raw_label = cv2.imread(os.path.join(directory_segmentations, '2007_000256' + \".png\"))\n",
        "#print(label[105:115, 130:140])\n",
        "print(label.shape)\n",
        "print(img.shape)\n",
        "print(VOC_CLASSES[12])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbHnVFAJs2TS"
      },
      "source": [
        "# Indexes for splitting the dataset into train, val, test\n",
        "\n",
        "'''\n",
        "filecount = len(filenames)\n",
        "indexes = []\n",
        "labels = []\n",
        "for index in range(filecount):\n",
        "     indexes.append(index)\n",
        "\n",
        "i=0\n",
        "for filename in filenames:\n",
        "    new_label = np.zeros(NUM_CLASSES)\n",
        "    new_label = [int(i) for i in new_label]\n",
        "    _, label = read_image_and_label(filename)\n",
        "    label = tf.argmax(label, axis=-1)\n",
        "    label = np.array(label)\n",
        "    label = label.reshape(256*256)\n",
        "    label = [int(i) for i in label]\n",
        "    \n",
        "    for cls in range(NUM_CLASSES):\n",
        "      if cls in label:\n",
        "        new_label[cls] = 1 # if class is present on the image, we are making it as multilabel one-hot encoding\n",
        "\n",
        "    labels.append(new_label)\n",
        "    print(i)\n",
        "    i+=1\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LYXC0K08wRV"
      },
      "source": [
        "'''\n",
        "indexes = np.array(indexes)\n",
        "labels = np.array(labels)\n",
        "training_indexes, X_valtest, y_train, y_valtest = iterative_train_test_split(indexes, labels, train_size = 0.7)\n",
        "validation_indexes, testing_indexes, y_val, y_test = iterative_train_test_split(X_valtest, y_valtest, train_size = 0.66)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PzDrr8gAbN8"
      },
      "source": [
        "'''\n",
        "print(len(training_indexes))\n",
        "print(len(y_train))\n",
        "print(len(testing_indexes))\n",
        "print(len(y_test))\n",
        "print(testing_indexes[:50])\n",
        "print(y_test[:10])\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5u4-L4T0Rbt",
        "outputId": "d3f23bb1-0278-431e-c41d-14192342f11d"
      },
      "source": [
        "'''\n",
        "num_train_samples = len(training_indexes)\n",
        "num_val_samples = len(validation_indexes)\n",
        "num_test_samples = len(testing_indexes)\n",
        "\n",
        "print(\"Num. training images\", num_train_samples)\n",
        "print(\"Num. val images\", num_val_samples)\n",
        "print(\"Num. test images\", num_test_samples)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num. training images 2039\n",
            "Num. val images 577\n",
            "Num. test images 297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7HfmB-l2YuR"
      },
      "source": [
        "# Save train, val, test index splits\n",
        "'''\n",
        "np.savetxt(DIR + 'VOC2012/Segmentation_indexes/seg_train_indexes.txt', training_indexes, fmt='%d')\n",
        "np.savetxt(DIR + 'VOC2012/Segmentation_indexes/seg_val_indexes.txt', validation_indexes, fmt='%d')\n",
        "np.savetxt(DIR + 'VOC2012/Segmentation_indexes/seg_test_indexes.txt', testing_indexes, fmt='%d')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mQlmCXo2Zzl"
      },
      "source": [
        "# Load train, val, test index splits\n",
        "training_indexes = np.loadtxt(DIR + 'VOC2012/Segmentation_indexes/seg_train_indexes.txt', dtype=int)\n",
        "validation_indexes = np.loadtxt(DIR + 'VOC2012/Segmentation_indexes/seg_val_indexes.txt', dtype=int)\n",
        "testing_indexes = np.loadtxt(DIR + 'VOC2012/Segmentation_indexes/seg_test_indexes.txt', dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39dKVe06SjTl"
      },
      "source": [
        "class DataGenerator(utils.all_utils.Sequence):\n",
        "  \n",
        "\n",
        "  def __init__(self, list_IDs, datafiles, batch_size = BATCH_SIZE, shuffle = True):\n",
        "    self.batch_size = batch_size\n",
        "    self.datafiles = datafiles\n",
        "    self.list_IDs = list_IDs\n",
        "    self.shuffle = shuffle\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  # After each epoch, shuffle the images if true\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(len(self.list_IDs))\n",
        "    if self.shuffle == True:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  # Generate images and labels for a batch\n",
        "  def __data_generation(self, list_IDs_temp):\n",
        "\n",
        "    # Initialization\n",
        "    X = np.empty((self.batch_size, IMG_WIDTH, IMG_HEIGHT, 1))\n",
        "    y = np.empty((self.batch_size, IMG_WIDTH, IMG_HEIGHT, NUM_CLASSES))\n",
        "\n",
        "    # For every image in the batch\n",
        "    for datactr in range (self.batch_size):\n",
        "      newimg, newlabel = read_image_and_label(self.datafiles[list_IDs_temp[datactr]])\n",
        "\n",
        "      y[datactr] = newlabel\n",
        "    \n",
        "      X[datactr] = newimg\n",
        "\n",
        "    return X, y\n",
        "\n",
        "  # Number of batches per epoch\n",
        "  def __len__(self):\n",
        "    return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "  # Generate indexes of the batch\n",
        "    newindexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "  # Find list of IDs\n",
        "    list_IDs_temp = [self.list_IDs[k] for k in newindexes]\n",
        "\n",
        "  # Generate data\n",
        "    X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QaQRuZsTIvw"
      },
      "source": [
        "training_generator = DataGenerator(training_indexes, filenames)\n",
        "val_generator = DataGenerator(validation_indexes, filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awrw8L_2Tbgt"
      },
      "source": [
        "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
        "    # weight initialization\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    # add downsampling layer\n",
        "    g = Conv2D(n_filters, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(layer_in)\n",
        "    # conditionally add batch normalization\n",
        "    if batchnorm:\n",
        "        g = BatchNormalization()(g, training=True)\n",
        "    # leaky relu activation\n",
        "    g = LeakyReLU(alpha=0.2)(g)\n",
        "    return g\n",
        "\n",
        "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
        "  # weight initialization\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  # add upsampling layer\n",
        "  g = Conv2DTranspose(n_filters, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(layer_in)\n",
        "  # add batch normalization\n",
        "  g = BatchNormalization()(g, training=True)\n",
        "  # conditionally add dropout\n",
        "  if dropout:\n",
        "      g = Dropout(0.5)(g, training=True)\n",
        "  # merge with skip connection\n",
        "  g = Concatenate()([g, skip_in])\n",
        "  # relu activation\n",
        "  g = Activation('relu')(g)\n",
        "  return g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F81h7d32TRAn"
      },
      "source": [
        "def define_generator(image_shape=(IMG_WIDTH, IMG_HEIGHT, 1)):\n",
        "    # weight initialization\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    # image input\n",
        "    in_image = Input(shape=image_shape)\n",
        "    # encoder model: C64-C128-C256-C512-C512-C512-C512-C512\n",
        "    e1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
        "    e2 = define_encoder_block(e1, 128)\n",
        "    e3 = define_encoder_block(e2, 256)\n",
        "    e4 = define_encoder_block(e3, 512)\n",
        "    e5 = define_encoder_block(e4, 512)\n",
        "    e6 = define_encoder_block(e5, 512)\n",
        "    e7 = define_encoder_block(e6, 512)\n",
        "    # bottleneck, no batch norm and relu\n",
        "    b = Conv2D(512, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(e7)\n",
        "    b = Activation('relu')(b)\n",
        "    # decoder model: CD512-CD512-CD512-CD512-C256-C128-C64\n",
        "    d1 = decoder_block(b, e7, 512)\n",
        "    d2 = decoder_block(d1, e6, 512)\n",
        "    d3 = decoder_block(d2, e5, 512)\n",
        "    d4 = decoder_block(d3, e4, 512, dropout=False)\n",
        "    d5 = decoder_block(d4, e3, 256, dropout=False)\n",
        "    d6 = decoder_block(d5, e2, 128, dropout=False)\n",
        "    d7 = decoder_block(d6, e1, 64, dropout=False)\n",
        "    # output\n",
        "    g = Conv2DTranspose(NUM_CLASSES, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d7)\n",
        "    out_image = Activation('softmax')(g)\n",
        "    # define model\n",
        "    model = Model(in_image, out_image)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utyTOxIS3Elm"
      },
      "source": [
        "def define_model_pretrained():\n",
        "  # load pre-trained generator\n",
        "  g_model = keras.models.load_model(GEN_PATH)\n",
        "  # change freezed or not\n",
        "  #g_model.trainable = False\n",
        "\n",
        "  # last layer before we add new layers\n",
        "  last_layer = 'activation_7'\n",
        "  new_generator = keras.Model(inputs=g_model.input, outputs=g_model.get_layer(last_layer).output)\n",
        "  #print(new_generator.summary())\n",
        "\n",
        "  x = new_generator.output\n",
        "  x = Conv2DTranspose(NUM_CLASSES, (4, 4), strides=(2, 2), padding='same', kernel_initializer=RandomNormal(stddev=0.02), name='last_conv2d')(x)\n",
        "  output = Activation('softmax', name='last_activation')(x)\n",
        "\n",
        "  segmentation_model = keras.Model(inputs=new_generator.input, outputs=output)\n",
        "\n",
        "  return segmentation_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CylyBacaT0eN",
        "outputId": "143b309b-9a86-4e0a-e16b-94ef1f5a4a34"
      },
      "source": [
        "# create the model\n",
        "#model = define_generator()\n",
        "model = define_model_pretrained() # change\n",
        "model.load_weights(saved_weights_path+'saved-weights-seg-coco-balanced-pretrained-01-2.17.hdf5')  #change\n",
        "\n",
        "# summarize the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 128, 128, 64) 1088        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 128, 128, 64) 0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 64, 64, 128)  131200      leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 64, 64, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 256)  524544      leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 16, 16, 512)  2097664     leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 16, 16, 512)  2048        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 8, 8, 512)    4194816     leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 8, 8, 512)    2048        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 8, 8, 512)    0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 4, 4, 512)    4194816     leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 4, 4, 512)    2048        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 4, 4, 512)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 2, 2, 512)    4194816     leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 2, 2, 512)    2048        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 2, 2, 512)    0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 1, 1, 512)    4194816     leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 1, 1, 512)    0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 2, 2, 512)    4194816     activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 2, 2, 512)    2048        conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2, 2, 512)    0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 2, 2, 1024)   0           dropout[0][0]                    \n",
            "                                                                 leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 2, 2, 1024)   0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 4, 4, 512)    8389120     activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 4, 4, 512)    2048        conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 4, 4, 512)    0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 4, 4, 1024)   0           dropout_1[0][0]                  \n",
            "                                                                 leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 4, 4, 1024)   0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 8, 8, 512)    8389120     activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 8, 8, 512)    2048        conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 8, 8, 512)    0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 8, 1024)   0           dropout_2[0][0]                  \n",
            "                                                                 leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 8, 8, 1024)   0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 16, 16, 512)  8389120     activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 512)  2048        conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 16, 16, 1024) 0           batch_normalization_9[0][0]      \n",
            "                                                                 leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 1024) 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 32, 32, 256)  4194560     activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 256)  1024        conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 512)  0           batch_normalization_10[0][0]     \n",
            "                                                                 leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 512)  0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 128)  1048704     activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 64, 64, 128)  512         conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 64, 64, 256)  0           batch_normalization_11[0][0]     \n",
            "                                                                 leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 64, 64, 256)  0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 128, 128, 64) 262208      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 128, 128, 64) 256         conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 128, 128, 128 0           batch_normalization_12[0][0]     \n",
            "                                                                 leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 128, 128, 128 0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "last_conv2d (Conv2DTranspose)   (None, 256, 256, 21) 43029       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "last_activation (Activation)    (None, 256, 256, 21) 0           last_conv2d[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 54,464,149\n",
            "Trainable params: 54,454,293\n",
            "Non-trainable params: 9,856\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2bCmwT9Ucds"
      },
      "source": [
        "MeanIou = tf.keras.metrics.MeanIoU(num_classes=21)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_2),\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=[MeanIou])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1A7FvQEV0m4"
      },
      "source": [
        "weights_save = ModelCheckpoint(saved_weights_path+'saved-weights-' + model_name + '-{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_weights_only=True, save_freq='epoch')\n",
        "\n",
        "history = model.fit(training_generator, \n",
        "validation_data=val_generator,\n",
        "use_multiprocessing=True,\n",
        "workers=6,\n",
        "epochs=EPOCHS,\n",
        "callbacks=[weights_save])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlu4jhoh9f9U"
      },
      "source": [
        "df = pd.DataFrame(history.history)\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['mean_io_u'])\n",
        "plt.plot(history.history['val_mean_io_u'])\n",
        "plt.title('model mIU')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xU6xtoLJ8s8"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-Ua3hPFChfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c3a1d1-777e-4225-ae00-008049057f5c"
      },
      "source": [
        "# change\n",
        "#model = define_generator()\n",
        "model = define_model_pretrained() # change\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.load_weights(saved_weights_path+'saved-weights-seg-coco-balanced-pretrained-10-1.09.hdf5')  #change\n",
        "\n",
        "#model = keras.models.load_model(saved_models_path + 'saved-model-scratch-seg-lab-gray-pre-epoch20') #change"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgYpCKqg9joZ"
      },
      "source": [
        "#load in the test set\n",
        "labels_test = []\n",
        "images_test = []\n",
        "for testing_index in testing_indexes:\n",
        "  image_test, label_test = read_image_and_label(filenames[testing_index])\n",
        "  labels_test.append(label_test)\n",
        "  images_test.append(image_test)\n",
        "  print(testing_index)\n",
        "\n",
        "images_test = np.array(images_test)\n",
        "labels_test = np.array(labels_test)\n",
        "\n",
        "loss, acc = model.evaluate(x=images_test,  y=labels_test, verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100*acc))\n",
        "print('Restored model, loss', loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu6MWDwWDkCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92cc6989-d51f-4b56-a6a4-c8bd1cc80a1a"
      },
      "source": [
        "# Save  model\n",
        "model.save(saved_models_path + 'saved-model-' + model_name) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Self-supervised-VOC/SavedModels/saved-model-seg-coco-balanced-pretrained/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64Ql5um99tl_"
      },
      "source": [
        "# Save history\n",
        "with open(DIR + 'TrainHistory/seg_pretarin_coco_history', 'wb') as file_pi: # change name\n",
        "    pickle.dump(history.history, file_pi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_RV3_MRYPPJ"
      },
      "source": [
        "## Plotting masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aBo3G8jYOO4"
      },
      "source": [
        "# Dictionary to map indexes to colors\n",
        "color_list = voc_colormap2label()\n",
        "color_list = list(color_list)\n",
        "print(color_list.index(1))\n",
        "\n",
        "color_dict = {}\n",
        "for i in range(NUM_CLASSES):\n",
        "  color_dict[i] = VOC_COLORMAP[i]\n",
        "print(color_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5DPFx5fRQpv"
      },
      "source": [
        "# Predicted mask (256,256,21)-> color mask image (256,256,3)\n",
        "def create_mask(pred_mask, color_dict):\n",
        "  mask = tf.argmax(pred_mask, axis=-1)\n",
        "  mask = mask[..., tf.newaxis]\n",
        "\n",
        "  mask = np.array(mask)\n",
        "  mask = mask.reshape(256*256)\n",
        "\n",
        "  mask = (pd.Series(mask)).map(color_dict) #convert the list to a pandas series temporarily before mapping\n",
        "  mask = list(mask)\n",
        "  mask = np.array(mask)\n",
        "  mask = mask.reshape(256,256,3)\n",
        "\n",
        "  return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psVhBEJGbgDw"
      },
      "source": [
        "index = 261\n",
        "subset = training_indexes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57jhi4fMRZbT"
      },
      "source": [
        "%pylab inline\n",
        "# Real mask\n",
        "image_test, label_test = read_image_and_label(filenames[subset[index]])\n",
        "image_test = np.array(image_test)\n",
        "label_test = np.array(label_test)\n",
        "mask = create_mask(label_test, color_dict)\n",
        "imgplot = plt.imshow(mask)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFDkVqyqZj_T"
      },
      "source": [
        "%pylab inline\n",
        "# Predicted mask\n",
        "image_test, _ = read_image_and_label(filenames[subset[index]])\n",
        "#image_test = np.array(image_test)\n",
        "image_test = image_test.reshape(1,256,256,1)\n",
        "label = model.predict(image_test)\n",
        "\n",
        "mask = create_mask(label, color_dict)\n",
        "imgplot = plt.imshow(mask)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkU5m4Skasac"
      },
      "source": [
        "# Image\n",
        "image = tf.keras.preprocessing.image.load_img(os.path.join(directory_images, filenames[subset[index]] + \".jpg\"), color_mode='rgb') # read image\n",
        "imgplot = plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8B5poQr7LBU"
      },
      "source": [
        "##mIU (mean intersection over union)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j8riYTV7S7h"
      },
      "source": [
        "#load in the test set\n",
        "labels_test = []\n",
        "pred_labels_test = []\n",
        "for testing_index in testing_indexes:\n",
        "\n",
        "  image_test, label_test = read_image_and_label(filenames[testing_index])\n",
        "\n",
        "  label_test = tf.argmax(label_test, axis=-1)\n",
        "  label_test = np.array(label_test)\n",
        "  labels_test.append(label_test)\n",
        "\n",
        "  pred_label = model.predict(image_test.reshape(1,256,256,1))\n",
        "  pred_label = tf.argmax(pred_label, axis=-1)\n",
        "  pred_label = np.array(pred_label)\n",
        "  pred_labels_test.append(pred_label)\n",
        "\n",
        "  print(testing_index)\n",
        "\n",
        "pred_labels_test = np.array(pred_labels_test)\n",
        "labels_test = np.array(labels_test)\n",
        "\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES)\n",
        "m.update_state(labels_test, pred_labels_test)\n",
        "m.result().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}